{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Features, Value, ClassLabel, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text = pd.read_csv(\"emotions_final.csv\", header=0, names=['label', 'text'])\n",
    "text.sample(3)\n",
    "\n",
    "emotions = text.label.unique()\n",
    "emotions\n",
    "\n",
    "class_names = list(emotions)\n",
    "emotion_features = Features({'text': Value('string'), 'label': ClassLabel(5,names=class_names)})\n",
    "\n",
    "labels = ClassLabel(5, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3cdbca8706c45705\n",
      "Reusing dataset csv (C:\\Users\\grace\\.cache\\huggingface\\datasets\\csv\\default-3cdbca8706c45705\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = load_dataset('csv', data_files='emotions_final.csv', column_names=['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset= sentences['train'].train_test_split(test_size=0.2, shuffle=True, seed=88).values()\n",
    "test_dataset, validation_dataset = test_dataset.train_test_split(test_size=0.3, shuffle=True, seed=88).values()\n",
    "sentences = DatasetDict({\"train\":train_dataset,\"test\": test_dataset, \"validation\": validation_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['text'], padding=True, truncation=True)\n",
    "    tokens['label'] = labels.str2int(batch['label'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.51ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.45ba/s]\n"
     ]
    }
   ],
   "source": [
    "emotions_encoded = sentences.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 1/1 [00:01<00:00,  1.82s/ba]\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00,  5.99ba/s]\n",
      "Casting the dataset: 100%|██████████| 1/1 [00:00<00:00, 18.18ba/s]\n"
     ]
    }
   ],
   "source": [
    "emotions_encoded = emotions_encoded.cast_column('label', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 5\n",
    "\n",
    "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(num_classes=5, names=['happiness', 'neutral', 'anxiety', 'sadness', 'anger'], id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(num_classes=5, names=['happiness', 'neutral', 'anxiety', 'sadness', 'anger'], id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "emotions_encoded[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
    "training_args = TrainingArguments(output_dir=\"results\",\n",
    "                                  num_train_epochs=10,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6261\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1096\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 470\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\grace\\.conda\\envs\\FYP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6261\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3920\n",
      " 10%|█         | 392/3920 [02:00<14:33,  4.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                  \n",
      " 10%|█         | 392/3920 [02:01<14:33,  4.04it/s]Saving model checkpoint to results\\checkpoint-392\n",
      "Configuration saved in results\\checkpoint-392\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6452142000198364, 'eval_accuracy': 0.7723404255319148, 'eval_f1': 0.7717691969876473, 'eval_runtime': 1.0782, 'eval_samples_per_second': 435.906, 'eval_steps_per_second': 27.824, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-392\\pytorch_model.bin\n",
      " 13%|█▎        | 500/3920 [02:34<16:51,  3.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8364, 'learning_rate': 1.7448979591836738e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 784/3920 [03:59<12:53,  4.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                  \n",
      " 20%|██        | 784/3920 [04:00<12:53,  4.05it/s]Saving model checkpoint to results\\checkpoint-784\n",
      "Configuration saved in results\\checkpoint-784\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6572643518447876, 'eval_accuracy': 0.7702127659574468, 'eval_f1': 0.7725313793055609, 'eval_runtime': 1.0462, 'eval_samples_per_second': 449.229, 'eval_steps_per_second': 28.674, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-784\\pytorch_model.bin\n",
      " 26%|██▌       | 1000/3920 [05:05<14:26,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4479, 'learning_rate': 1.4897959183673472e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1176/3920 [05:57<11:04,  4.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 30%|███       | 1176/3920 [05:58<11:04,  4.13it/s]Saving model checkpoint to results\\checkpoint-1176\n",
      "Configuration saved in results\\checkpoint-1176\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6375669836997986, 'eval_accuracy': 0.8021276595744681, 'eval_f1': 0.8014495146848897, 'eval_runtime': 1.0207, 'eval_samples_per_second': 460.474, 'eval_steps_per_second': 29.392, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-1176\\pytorch_model.bin\n",
      " 38%|███▊      | 1500/3920 [07:35<11:48,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.272, 'learning_rate': 1.2346938775510204e-05, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1568/3920 [07:55<09:30,  4.12it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 40%|████      | 1568/3920 [07:56<09:30,  4.12it/s]Saving model checkpoint to results\\checkpoint-1568\n",
      "Configuration saved in results\\checkpoint-1568\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8435006737709045, 'eval_accuracy': 0.7936170212765957, 'eval_f1': 0.7936145278637838, 'eval_runtime': 1.0145, 'eval_samples_per_second': 463.296, 'eval_steps_per_second': 29.572, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-1568\\pytorch_model.bin\n",
      " 50%|█████     | 1960/3920 [09:52<07:58,  4.10it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 50%|█████     | 1960/3920 [09:53<07:58,  4.10it/s]Saving model checkpoint to results\\checkpoint-1960\n",
      "Configuration saved in results\\checkpoint-1960\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9125773906707764, 'eval_accuracy': 0.7978723404255319, 'eval_f1': 0.7991018728303025, 'eval_runtime': 1.019, 'eval_samples_per_second': 461.252, 'eval_steps_per_second': 29.442, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-1960\\pytorch_model.bin\n",
      " 51%|█████     | 2000/3920 [10:06<09:25,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1389, 'learning_rate': 9.795918367346939e-06, 'epoch': 5.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2352/3920 [11:49<06:18,  4.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 60%|██████    | 2352/3920 [11:50<06:18,  4.15it/s]Saving model checkpoint to results\\checkpoint-2352\n",
      "Configuration saved in results\\checkpoint-2352\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0749258995056152, 'eval_accuracy': 0.7872340425531915, 'eval_f1': 0.7880043918313167, 'eval_runtime': 1.0132, 'eval_samples_per_second': 463.863, 'eval_steps_per_second': 29.608, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-2352\\pytorch_model.bin\n",
      " 64%|██████▍   | 2500/3920 [12:36<07:02,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0852, 'learning_rate': 7.244897959183675e-06, 'epoch': 6.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2744/3920 [13:48<04:48,  4.08it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 70%|███████   | 2744/3920 [13:49<04:48,  4.08it/s]Saving model checkpoint to results\\checkpoint-2744\n",
      "Configuration saved in results\\checkpoint-2744\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0908101797103882, 'eval_accuracy': 0.7893617021276595, 'eval_f1': 0.7887452642560124, 'eval_runtime': 1.0482, 'eval_samples_per_second': 448.371, 'eval_steps_per_second': 28.619, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-2744\\pytorch_model.bin\n",
      " 77%|███████▋  | 3000/3920 [15:07<04:32,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0592, 'learning_rate': 4.693877551020409e-06, 'epoch': 7.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3136/3920 [15:48<03:15,  4.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 80%|████████  | 3136/3920 [15:49<03:15,  4.02it/s]Saving model checkpoint to results\\checkpoint-3136\n",
      "Configuration saved in results\\checkpoint-3136\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1592433452606201, 'eval_accuracy': 0.8, 'eval_f1': 0.8002943848144972, 'eval_runtime': 1.0662, 'eval_samples_per_second': 440.8, 'eval_steps_per_second': 28.136, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-3136\\pytorch_model.bin\n",
      " 89%|████████▉ | 3500/3920 [17:38<02:05,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0381, 'learning_rate': 2.1428571428571427e-06, 'epoch': 8.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3528/3920 [17:46<01:37,  4.03it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 90%|█████████ | 3528/3920 [17:47<01:37,  4.03it/s]Saving model checkpoint to results\\checkpoint-3528\n",
      "Configuration saved in results\\checkpoint-3528\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1812270879745483, 'eval_accuracy': 0.8042553191489362, 'eval_f1': 0.8043095167183316, 'eval_runtime': 1.0522, 'eval_samples_per_second': 446.667, 'eval_steps_per_second': 28.511, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-3528\\pytorch_model.bin\n",
      "100%|██████████| 3920/3920 [19:45<00:00,  4.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "                                                   \n",
      "100%|██████████| 3920/3920 [19:46<00:00,  4.11it/s]Saving model checkpoint to results\\checkpoint-3920\n",
      "Configuration saved in results\\checkpoint-3920\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.211344599723816, 'eval_accuracy': 0.7957446808510639, 'eval_f1': 0.7958733479510078, 'eval_runtime': 1.0447, 'eval_samples_per_second': 449.871, 'eval_steps_per_second': 28.715, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-3920\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results\\checkpoint-3528 (score: 0.8043095167183316).\n",
      "100%|██████████| 3920/3920 [19:48<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1188.3976, 'train_samples_per_second': 52.684, 'train_steps_per_second': 3.299, 'train_loss': 0.24288988964898245, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded[\"train\"],\n",
    "                  eval_dataset=emotions_encoded[\"validation\"])\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 470\n",
      "  Batch size = 16\n",
      "100it [00:10,  9.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1812270879745483,\n",
       " 'eval_accuracy': 0.8042553191489362,\n",
       " 'eval_f1': 0.8043095167183316,\n",
       " 'eval_runtime': 1.3743,\n",
       " 'eval_samples_per_second': 342.003,\n",
       " 'eval_steps_per_second': 21.83,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1096\n",
      "  Batch size = 16\n",
      "100%|██████████| 69/69 [00:03<00:00, 21.54it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.189466953277588,\n",
       " 'test_accuracy': 0.781021897810219,\n",
       " 'test_f1': 0.7798639468951565,\n",
       " 'test_runtime': 3.5763,\n",
       " 'test_samples_per_second': 306.459,\n",
       " 'test_steps_per_second': 19.293}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(emotions_encoded[\"test\"])\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    result = tokenizer(examples['sentence'], padding=False, max_length=None, truncation=True, verbose=False)\n",
    "    return result\n",
    "\n",
    "def predict(dataframe):\n",
    "    eval_dataset = Dataset.from_pandas(dataframe)\n",
    "    eval_dataset = eval_dataset.map(preprocess_function, batched=False, load_from_cache_file=True)\n",
    "    # Initialize our Trainer\n",
    "    predictions = trainer.predict(test_dataset=eval_dataset).predictions\n",
    "    # Adding a softmax layer to get probabilities. If you want class labels instead -  np.argmax(predictions, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?ex/s]\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neutral'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = pd.DataFrame([''], columns=['sentence'])\n",
    "predictions = predict(example)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "emotions[predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:16, 21.54it/s]                        "
     ]
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./model\\config.json\n",
      "Model weights saved in ./model\\pytorch_model.bin\n",
      "tokenizer config file saved in ./model\\tokenizer_config.json\n",
      "Special tokens file saved in ./model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model\\\\tokenizer_config.json',\n",
       " './model\\\\special_tokens_map.json',\n",
       " './model\\\\vocab.txt',\n",
       " './model\\\\added_tokens.json',\n",
       " './model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./model')\n",
    "tokenizer.save_pretrained('./model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f206b6c75a13f92bc97dfa1e930151b21df17184be9d9c72a2ae387f01f205b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('FYP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
